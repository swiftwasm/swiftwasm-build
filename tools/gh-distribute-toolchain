#!/usr/bin/env python3
# gh-distribute-toolchain - A script to distribute a toolchain to GitHub
# It does the following:
# 1. Download the toolchain artifacts from the given run
# 2. Create a git tag for the swiftwasm/swift repo with the patches
# 3. Push the tag to the swiftwasm/swift repo
# 4. Create a GitHub release for the tag with the toolchain artifacts
import os
import sys
import subprocess
import tarfile
import asyncio
from dataclasses import dataclass
from typing import Optional
from build.build_support.actions import derive_options_from_args, REPO_ROOT


USER_AGENT = "gh-distribute-toolchain by swiftwasm/swiftwasm-build"


@dataclass
class Secrets:
    DARWIN_TOOLCHAIN_APPLICATION_CERT: str
    DARWIN_TOOLCHAIN_INSTALLER_CERT: str
    DARWIN_TOOLCHAIN_NOTARIZE_EMAIL: str
    DARWIN_TOOLCHAIN_NOTARIZE_TEAM_ID: str
    DARWIN_TOOLCHAIN_NOTARIZE_PASSWORD: str
    GITHUB_TOKEN: str

    @staticmethod
    def derive():
        github_token = Secrets.env_value("GITHUB_TOKEN")
        if github_token is None:
            result = subprocess.run(
                ["gh", "auth", "token"], capture_output=True, check=False)
            if result.returncode != 0:
                raise Exception(("Failed to get GitHub token "
                                 "from GITHUB_TOKEN and gh auth token"))
            github_token = result.stdout.decode("utf-8").strip()

        return Secrets(
            DARWIN_TOOLCHAIN_APPLICATION_CERT=Secrets.env_value(
                "DARWIN_TOOLCHAIN_APPLICATION_CERT"),
            DARWIN_TOOLCHAIN_INSTALLER_CERT=Secrets.env_value(
                "DARWIN_TOOLCHAIN_INSTALLER_CERT"),
            DARWIN_TOOLCHAIN_NOTARIZE_EMAIL=Secrets.env_value(
                "DARWIN_TOOLCHAIN_NOTARIZE_EMAIL"),
            DARWIN_TOOLCHAIN_NOTARIZE_TEAM_ID=Secrets.env_value(
                "DARWIN_TOOLCHAIN_NOTARIZE_TEAM_ID"),
            DARWIN_TOOLCHAIN_NOTARIZE_PASSWORD=Secrets.env_value(
                "DARWIN_TOOLCHAIN_NOTARIZE_PASSWORD"),
            GITHUB_TOKEN=github_token,
        )

    @staticmethod
    def env_value(key: str):
        return os.environ.get(key)


class DarwinToolchainPackaging:
    def __init__(self, secrets: Secrets,
                 dry_run: bool = False, verbose: bool = False):
        self.secrets = secrets
        self.dry_run = dry_run
        self.verbose = verbose

    async def package(self, toolchain_dir: str, tag_name: str, pkg_path: str,
                swift_source_dir: str):
        self.update_info_plist(toolchain_dir)
        self.sign_darwin_toolchain(toolchain_dir)
        await self.create_installer(toolchain_dir, pkg_path, tag_name, swift_source_dir)

    def update_info_plist(self, toolchain_dir: str):
        display_name = os.environ.get("DARWIN_TOOLCHAIN_DISPLAY_NAME")
        info_plist = f"{toolchain_dir}/Info.plist"
        if display_name:
            subprocess.check_output([
                "/usr/libexec/PlistBuddy",
                "-c", f"Set DisplayName {display_name}", info_plist
            ])

        display_name_short = os.environ.get(
            "DARWIN_TOOLCHAIN_DISPLAY_NAME_SHORT")
        if display_name_short:
            subprocess.check_output([
                "/usr/libexec/PlistBuddy",
                "-c", f"Set ShortDisplayName {display_name_short}", info_plist
            ])

    def sign_darwin_toolchain(self, toolchain_dir: str):
        if self.secrets.DARWIN_TOOLCHAIN_APPLICATION_CERT is None:
            raise Exception("Missing DARWIN_TOOLCHAIN_APPLICATION_CERT")

        codesign_args = [
            "/usr/bin/codesign",
            "--force", "--verify", "--verbose", "--deep",
            "--options", "runtime", "--timestamp",
            "--sign", self.secrets.DARWIN_TOOLCHAIN_APPLICATION_CERT
        ]

        for root, dirs, files in os.walk(toolchain_dir):
            for file in files:
                path = os.path.join(root, file)
                if not self.is_macho_binary(path):
                    continue
                self.subprocess_run(codesign_args + [path], check=True)

        self.subprocess_run(codesign_args + [toolchain_dir], check=True)

    async def create_installer(self, toolchain_dir: str, pkg_path: str,
                               tag_name: str, swift_source_dir: str):
        toolchain_name = tag_name
        toolchain_installer_package = pkg_path
        toolchain_install_location = (
            f"/Library/Developer/Toolchains/{toolchain_name}.xctoolchain")
        toolchain_version = subprocess.check_output([
            "/usr/libexec/PlistBuddy",
            "-c", "Print Version string",
            f"{toolchain_dir}/Info.plist"
        ]).decode("utf-8")
        toolchain_bundle_identifier = subprocess.check_output([
            "/usr/libexec/PlistBuddy",
            "-c", "Print CFBundleIdentifier string",
            f"{toolchain_dir}/Info.plist"
        ]).decode("utf-8")

        self.subprocess_run([
            f"{swift_source_dir}/utils/toolchain-installer", toolchain_dir,
            toolchain_bundle_identifier,
            self.secrets.DARWIN_TOOLCHAIN_INSTALLER_CERT,
            toolchain_installer_package,
            toolchain_install_location,
            toolchain_version,
            f"{swift_source_dir}/utils/darwin-installer-scripts"
        ], check=True)

        await self.check_async_subprocess(
            "xcrun", "notarytool", "submit",
            toolchain_installer_package,
            "--wait",
            "--apple-id", self.secrets.DARWIN_TOOLCHAIN_NOTARIZE_EMAIL,
            "--team-id", self.secrets.DARWIN_TOOLCHAIN_NOTARIZE_TEAM_ID,
            "--password", self.secrets.DARWIN_TOOLCHAIN_NOTARIZE_PASSWORD)

        self.subprocess_run(["xcrun", "stapler", "staple",
                             toolchain_installer_package], check=True)

    def subprocess_run(self, args, **kwargs):
        """
        Run a non-mutating subprocess and print the command if
        verbose or dry_run is True.
        """
        if self.verbose or self.dry_run:
            print(" ".join(args))
        return subprocess.run(args, **kwargs)

    async def check_async_subprocess(self, program, *args):
        if self.verbose or self.dry_run:
            print(f"[async] {program} {' '.join(args)}")
        if self.dry_run:
            return
        proc = await asyncio.subprocess.create_subprocess_exec(program, *args)
        retcode = await proc.wait()
        if retcode != 0:
            raise Exception(f"Failed to execute: {' '.join(args)}")

    def is_macho_binary(self, file_path):
        if not os.path.exists(file_path):
            return False
        magic_bytes = None
        with open(file_path, mode="rb") as f:
            magic_bytes = f.read(4)
        macho_bytes = [
            [0xca, 0xfe, 0xba, 0xbe],  # Mach-O Fat Binary
            [0xcf, 0xfa, 0xed, 0xfe],  # Mach-O 64-bit executable
            [0xce, 0xfa, 0xed, 0xfe],  # Mach-O 32-bit executable
        ]
        for b in macho_bytes:
            if magic_bytes == bytes(b):
                return True
        return False


class GitHub:
    def __init__(self, token: str, repo: str = "swiftwasm/swiftwasm-build"):
        self.token = token
        self.repo = repo

    def list_artifacts(self, run_id: str):
        page = 1
        per_page = 30
        artifacts = []
        while True:
            url = ("https://api.github.com"
                   f"/repos/{self.repo}/actions/runs/{run_id}/artifacts"
                   f"?page={page}&per_page={per_page}")
            response = self.json_request("GET", url)
            if "artifacts" not in response:
                raise Exception(f"Unexpected response: {response}")
            artifacts += response["artifacts"]
            if len(response["artifacts"]) < per_page:
                break
            page += 1
        return artifacts

    def revision_at_run(self, run_id: str):
        url = ("https://api.github.com"
               f"/repos/{self.repo}/actions/runs/{run_id}")
        response = self.json_request("GET", url)
        return response["head_sha"]

    def get_release(self, tag_name: str):
        url = ("https://api.github.com"
               f"/repos/{self.repo}/releases/tags/{tag_name}")
        return self.json_request("GET", url)

    def create_prerelease(self, tag_name: str):
        url = f"https://api.github.com/repos/{self.repo}/releases"
        return self.json_request("POST", url, body={
            "tag_name": tag_name,
            "name": tag_name,
            "prerelease": True,
        })

    def workflow_runs(self, workflow_name: str, branch: str):
        url = ("https://api.github.com"
               f"/repos/{self.repo}/actions/workflows/{workflow_name}"
               f"/runs?branch={branch}")
        run = self.json_request("GET", url)
        workflow_runs = run["workflow_runs"]
        workflow_runs = sorted(
            workflow_runs, key=lambda run: run["run_number"], reverse=True)
        return workflow_runs

    async def download_artifact(self, artifact, path: str):
        curl_args = ["curl", "-L", "-s", "--show-error", "-o", path,
                     artifact["archive_download_url"],
                     "--header", f"Authorization: Bearer {self.token}"]
        proc = await asyncio.subprocess.create_subprocess_exec(
            curl_args[0], *curl_args[1:])
        returncode = await proc.wait()
        if returncode != 0:
            raise Exception(f"\"{' '.join(curl_args)}\" failed")

    def upload_release_asset(self, release_id: str, asset_path: str):
        content_len = os.path.getsize(asset_path)
        filename = os.path.basename(asset_path)
        url = (f"https://uploads.github.com/repos/{self.repo}/"
               f"releases/{release_id}/assets?name={filename}")
        curl_args = ["curl", "-XPOST",
                     "--header", f"Authorization: Bearer {self.token}",
                     "--header", f"Content-Length: {content_len}",
                     "--header", "Content-Type: application/x-gzip",
                     "--upload-file", asset_path,
                     url]
        subprocess.run(curl_args, check=True)

    def json_request(self, method: str, path: str,
                     body: Optional[dict] = None):
        import json
        headers = {"Accept": "application/vnd.github.v3+json"}
        data = None
        if body:
            data = json.dumps(body).encode("utf-8")
        resp = self.request(method, path, headers=headers, data=data)
        return json.loads(resp.read())

    def request(self, method: str, url: str, headers: dict,
                data: Optional[bytes] = None):
        headers = headers.copy()
        headers["Authorization"] = f"Bearer {self.token}"
        headers["User-Agent"] = USER_AGENT

        import urllib.request
        req = urllib.request.Request(url, headers=headers, method=method,
                                     data=data)
        resp = urllib.request.urlopen(req)
        if resp.status < 200 or 300 <= resp.status:
            raise Exception(
                ("GitHub API request failed: "
                 f"{resp.status} {resp.reason} {resp.read().decode('utf-8')}"))
        return resp


class Distribution:
    def __init__(self, github: GitHub, swift_github: GitHub,
                 run_id: str, secrets: Secrets, dry_run: bool = False, verbose: bool = False):
        self.github = github
        self.swift_github = swift_github
        self.run_id = run_id
        self.secrets = secrets
        self.dry_run = dry_run
        self.verbose = verbose
        self.distribution_dir = os.path.join(
            os.path.dirname(REPO_ROOT), "build", "Distribution")
        self.artifacts_dir = os.path.join(
            self.distribution_dir, "artifacts", self.run_id)
        self.checkout_dir = os.path.join(
            self.distribution_dir, "checkout")

    async def run(self, options):
        downloads = []
        for artifact in self.toolchain_artifacts(options):
            platform_suffix, scheme = derive_platform_suffix_and_scheme(
                artifact["name"])
            if options.scheme != scheme:
                print(f"Skipping {artifact['name']} because it's not scheme {options.scheme}")
                # Skip unrelated artifact
                continue

            async def download_work(artifact, platform_suffix):
                downloaded_path = await self.download_artifact(artifact)
                return [artifact, downloaded_path, platform_suffix]

            print((f"Downloading {artifact['name']} from "
                   f"{artifact['archive_download_url']}..."))
            downloads.append(
                asyncio.create_task(download_work(artifact, platform_suffix)))

        try:
            downloaded_paths = await asyncio.gather(*downloads)
        except Exception as e:
            print(f"Download task failed: {e}, cancelling all tasks")
            for task in downloads:
                task.cancel()
            raise e

        if options.verbose:
            print("Downloaded paths:")
            for artifact, artifact_path, platform_suffix in downloaded_paths:
                print(f"  {artifact['name']} -> {artifact_path}")

        release = None
        tag_name = options.override_name

        # Create tag and release on GitHub
        for artifact, artifact_path, platform_suffix in downloaded_paths:
            if not artifact["name"].endswith("-installable"):
                continue

            artifact_path = self.unpack_toolchain(artifact_path)
            if not tag_name:
                tag_name = self.guess_tag_name(artifact_path)
            release = self.create_tag_and_prerelease(tag_name, options)
            break

        # Move to artifacts directory because "zip" does not have
        # --chdir option unlike "tar"
        os.chdir(self.artifacts_dir)

        packaging_tasks = []
        # Package and upload Swift SDK artifactbundles
        for downloaded in downloaded_paths:
            artifact, _, _ = downloaded
            if not artifact["name"].endswith("-artifactbundle"):
                continue

            async def package_sdk_work(downloaded):
                artifact, artifact_path, platform_suffix = downloaded
                bundle_path = await self.unpack_artifactbundle(artifact_path)
                package = await self.package_artifactbundle(
                    bundle_path, tag_name, platform_suffix)
                if options.dry_run:
                    print(f"Skip uploading actual artifact \"{package}\"")
                    return
                self.upload_to_release(package, release)

            print(f"Packaging {artifact['name']}...")
            packaging_tasks.append(
                asyncio.create_task(package_sdk_work(downloaded)))

        try:
            await asyncio.gather(*packaging_tasks)
        except Exception as e:
            print(f"Some of packaging tasks failed: {e}, cancelling all tasks")
            for task in packaging_tasks:
                task.cancel()
            raise e

        if options.only_swift_sdk:
            return

        # Package and upload toolchains
        for artifact, artifact_path, platform_suffix in downloaded_paths:
            if not artifact["name"].endswith("-installable"):
                continue

            artifact_path = self.unpack_toolchain(artifact_path)
            package = await self.package_toolchain(
                artifact_path, tag_name, platform_suffix)
            if options.dry_run:
                print(f"Skip uploading actual artifact \"{package}\"")
                continue
            self.upload_to_release(package, release)

    def guess_tag_name(self, path):
        return os.path.basename(path)

    async def package_toolchain(self, artifact_path: str, tag_name: str,
                                platform_suffix: str):
        print(f"Packaging {artifact_path}")
        import shutil
        dest_dir = os.path.dirname(artifact_path)
        artifacts_path = os.path.dirname(dest_dir)

        if os.path.basename(artifact_path) != tag_name:
            # e.g.
            # dest_dir:
            # <run-id>/swift-wasm-DEVELOPMENT-SNAPSHOT-amazonlinux2_x86_64
            # artifact_path:
            # <dest-dir>/swift-wasm-DEVELOPMENT-SNAPSHOT-2023-6-25-a
            # dest_path:
            # <dest-dir>/swift-wasm-DEVELOPMENT-SNAPSHOT-2023-6-25-b
            print(f"Re-package {artifact_path} as {tag_name}")
            dest_path = os.path.join(dest_dir, tag_name)
            shutil.rmtree(dest_path, ignore_errors=True)
            shutil.move(artifact_path, dest_path)
            artifact_path = dest_path

        if platform_suffix.startswith("macos_"):
            pkg_path = os.path.join(
                artifacts_path, f"{tag_name}-{platform_suffix}.pkg")
            if os.path.exists(pkg_path):
                return pkg_path
            swift_source_dir = os.path.join(self.checkout_dir, "swift")
            await DarwinToolchainPackaging(
                self.secrets, self.dry_run, self.verbose
            ).package(artifact_path, tag_name, pkg_path, swift_source_dir)
            return pkg_path
        else:
            tarball_path = os.path.join(
                artifacts_path, f"{tag_name}-{platform_suffix}.tar.gz")
            if os.path.exists(tarball_path):
                return tarball_path
            tar_args = ["tar", "cfz", tarball_path,
                        "-C", os.path.dirname(artifact_path),
                        os.path.basename(artifact_path)]
            self.subprocess_run(tar_args, check=True)
            return tarball_path

    async def package_artifactbundle(self, artifact_path: str, tag_name: str,
                                     platform_suffix: str):
        import shutil
        print(f"Packaging {artifact_path}")
        dirents = os.listdir(artifact_path)
        if len(dirents) != 2:
            raise Exception((
                f"Unexpected number of files in {artifact_path}:"
                f" {len(dirents)} (expected 2)"))
        info_json = os.path.join(artifact_path, "info.json")
        dirents.remove(os.path.basename(info_json))
        sdk_artifact_id = dirents[0]
        sdk_path = os.path.join(artifact_path, sdk_artifact_id)

        expected_artifact_id = tag_name.lstrip("swift-wasm") + "-wasm"
        if sdk_artifact_id != expected_artifact_id:
            print((f"Re-packaging artifactbundle: "
                  f"{sdk_artifact_id} -> {expected_artifact_id}"))
            new_sdk_path = os.path.join(artifact_path, expected_artifact_id)
            shutil.move(sdk_path, new_sdk_path)

            # Replace artifact id in info.json
            self.rename_artifact_id(
                info_json, sdk_artifact_id, expected_artifact_id)
            sdk_path = new_sdk_path
            sdk_artifact_id = expected_artifact_id

        # Rename .artifactbundle file name
        tagged_artifact_path = os.path.join(
            os.path.dirname(artifact_path),
            f"{tag_name}-{platform_suffix}.artifactbundle")
        bundlezip_path = tagged_artifact_path + ".zip"

        if not os.path.exists(tagged_artifact_path):
            shutil.move(artifact_path, tagged_artifact_path)

        if os.path.exists(bundlezip_path):
            return bundlezip_path
        # Re-zip artifactbundle
        print((f"Re-zipping artifactbundle {tagged_artifact_path}"
               f" to {bundlezip_path}"))

        # Due to lack of "--chdir", we chdir to artifacts dir before
        # packaging works.
        assert os.getcwd() == self.artifacts_dir
        relative_tagged_artifact_path = os.path.relpath(tagged_artifact_path)
        assert relative_tagged_artifact_path == os.path.basename(tagged_artifact_path)

        zip_proc = await asyncio.subprocess.create_subprocess_exec(
            "zip", "-r", "-y", "-q",
            bundlezip_path, relative_tagged_artifact_path)
        if await zip_proc.wait() != 0:
            raise Exception(f"Failed to zip {tagged_artifact_path}")
        return bundlezip_path

    def rename_artifact_id(self, info_json_path, old_id, new_id):
        print(f"Renaming artifact id: {old_id} -> {new_id}")
        with open(info_json_path, "r") as f:
            contents = f.read()
        contents = contents.replace(old_id, new_id)
        with open(info_json_path, "w") as f:
            f.write(contents)

    def unzip_artifact(self, artifact_zip):
        print(f"Unpacking {artifact_zip}...")
        # Get the list of files in the .zip file
        contents = subprocess.check_output(["zipinfo", "-1", artifact_zip])
        contents = contents.decode("utf-8").splitlines()
        if len(contents) != 1:
            raise Exception(
                (f"Unexpected number of files in {artifact_zip}:"
                 f" {len(contents)} (expected 1)"))

        content_name = contents[0]
        content_path = os.path.join(
            os.path.dirname(artifact_zip), content_name)

        if not os.path.exists(content_path):
            self.effect_run(["unzip", artifact_zip, "-d",
                            os.path.dirname(content_path)], check=True)
        return [content_name, content_path]

    async def unpack_artifactbundle(self, zip_bundlezip):
        artifact_name, bundlezip_path = self.unzip_artifact(zip_bundlezip)
        bundle_path, _ = os.path.splitext(bundlezip_path)
        if os.path.exists(bundle_path):
            print(f"Already unzipped: {bundle_path}")
            return bundle_path
        print(f"Unzipping .artifactbundle.zip: {bundlezip_path}")
        await self.check_async_subprocess(
            "unzip", "-q", bundlezip_path, "-d", os.path.dirname(bundle_path))
        return bundle_path

    def unpack_toolchain(self, zip_tarball):
        tarball_name, tarball_path = self.unzip_artifact(zip_tarball)

        # Remove the .tar.gz extension
        tarball_basename = os.path.splitext(
            os.path.splitext(tarball_name)[0])[0]
        tarball_output_dir = os.path.join(
            os.path.dirname(tarball_path), tarball_basename)
        if not os.path.exists(tarball_output_dir):
            os.makedirs(tarball_output_dir, exist_ok=True)
            print(f"Extracting {tarball_path}...")
            with tarfile.open(tarball_path, "r:gz") as tar:
                tar.extractall(tarball_output_dir)
        else:
            print(f"Tarball already extracted at {tarball_output_dir}")

        dirents = os.listdir(tarball_output_dir)
        if len(dirents) != 1:
            raise Exception((
                f"Unexpected number of files in {tarball_output_dir}:"
                f" {len(dirents)} (expected 1)"))
        return os.path.join(tarball_output_dir, dirents[0])

    async def download_artifact(self, artifact):
        if not os.path.exists(self.artifacts_dir):
            os.makedirs(self.artifacts_dir, exist_ok=True)
        path = os.path.join(self.artifacts_dir, artifact["name"])
        if os.path.exists(path):
            print(f"Artifact already exists at {path}")
            return path
        await self.github.download_artifact(artifact, path)
        print(f"Downloaded {artifact['name']}")
        return path

    def create_tag_and_prerelease(self, tag_name, options):
        print(f"Creating tag for {tag_name}...")
        self.git_push_swift_source(options, tag_name)
        try:
            # If release already exists, use it
            release = self.swift_github.get_release(tag_name)
            print(f"Use existing prerelease for {tag_name}...")
            return release
        except Exception:
            pass
        print(f"Creating prerelease for {tag_name}...")
        return self.swift_github.create_prerelease(tag_name)

    def git_push_swift_source(self, options, tag_name):
        build_repo = "https://github.com/swiftwasm/swiftwasm-build.git"
        build_rev = self.github.revision_at_run(self.run_id)

        os.makedirs(self.checkout_dir, exist_ok=True)
        build_repo_dir = os.path.join(self.checkout_dir, "swiftwasm-build")
        if not os.path.exists(build_repo_dir):
            self.subprocess_run(["git", "clone", build_repo,
                                build_repo_dir], check=True)

        self.subprocess_run(["git", "-C", build_repo_dir,
                            "fetch", "origin"], check=True)
        self.subprocess_run(["git", "-C", build_repo_dir,
                             "checkout", build_rev], check=True)

        # Checkout swift repository and apply patches at the build revision
        git_swift_workspace = os.path.join(
            build_repo_dir, "tools", "git-swift-workspace")
        self.subprocess_run([git_swift_workspace, "--scheme",
                            options.scheme], check=True)

        swift_repo_dir = os.path.join(self.checkout_dir, "swift")

        fork_repo = 'git@github.com:swiftwasm/swift.git'
        status = self.subprocess_run(['git', '-C', swift_repo_dir,
                                      'remote', 'get-url', 'swiftwasm']).returncode
        if status != 0:
            self.effect_run(['git', '-C', swift_repo_dir, 'remote',
                            'add', 'swiftwasm', fork_repo], check=True)

        # Fetch the tag from the fork. This can fail if the tag doesn't exist
        self.subprocess_run(['git', '-C', swift_repo_dir,
                            'fetch', 'swiftwasm', 'tag', tag_name, '--no-tags'])

        status = subprocess.run([
            'git', '-C', swift_repo_dir,
            'tag', '--list', '--contains', tag_name]).returncode
        if status == 0:
            print(f"Tag {tag_name} already exists")
            return

        self.effect_run(["git", "-C", swift_repo_dir, "tag", tag_name], check=True)
        self.effect_run(["git", "-C", swift_repo_dir,
                        "push", "swiftwasm", tag_name], check=True)

    def upload_to_release(self, artifact_path, release):
        name = os.path.basename(artifact_path)
        if "assets" in release:
            for asset in release["assets"]:
                asset_name = asset["name"]
                if os.path.basename(artifact_path) == asset_name:
                    print((f"{name} is already uploaded"
                           f" to release {release['name']}"))
                    return
        print(f"Uploading {name} to release {release['name']}...")
        self.swift_github.upload_release_asset(release['id'], artifact_path)

    def toolchain_artifacts(self, options):
        artifacts = self.github.list_artifacts(self.run_id)
        for artifact in artifacts:
            artifact_name = artifact["name"]
            should_yield = artifact_name.endswith("-artifactbundle") or \
                artifact_name.endswith("-installable")
            if should_yield:
                yield artifact

    def subprocess_run(self, args, **kwargs):
        """
        Run a non-mutating subprocess and print the command if
        verbose or dry_run is True.
        """
        if self.verbose or self.dry_run:
            print(" ".join(args))
        return subprocess.run(args, **kwargs)

    def effect_run(self, args, **kwargs):
        """
        Run a mutating subprocess and print the command if
        verbose or dry_run is True.
        """
        if self.verbose or self.dry_run:
            print(" ".join(args))
        if self.dry_run:
            return
        return subprocess.run(args, **kwargs)

    async def check_async_subprocess(self, program, *args):
        if self.verbose or self.dry_run:
            print(f"[async] {program} {' '.join(args)}")
        if self.dry_run:
            return
        proc = await asyncio.subprocess.create_subprocess_exec(program, *args)
        retcode = await proc.wait()
        if retcode != 0:
            raise Exception(f"Failed to execute: {' '.join(args)}")


def derive_platform_suffix_and_scheme(artifact_name: str):
    """
    Returns platform suffix derived from the artifact name.
    e.g. macos_x86_64
    """

    # latest artifact name: <platform-suffix>-<scheme>-installable
    # legacy artifact name: <platform-suffix>-installable
    # Note that <scheme> can contain '-'.
    name: str = artifact_name
    artifact_suffixes = ("-installable", "-artifactbundle")
    if not name.endswith(artifact_suffixes):
        raise Exception((f"Unexpected artifact name {name}"
                         f", expected to have one of \"{artifact_suffixes}\""
                         " suffix"))
    components = name.split("-")
    if len(components) >= 3:
        scheme = "-".join(components[1:-1])
        return [components[0], scheme]
    else:
        # Assume legacy representation only used for the main scheme
        return [components[0], "main"]


def latest_success_run_id(gh: GitHub, workflow_name: str, branch: str, scheme: str):
    """
    Find the latest successful run ID for the given workflow name and branch,
    also containing a toolchain artifact built for the given scheme
    """
    for run in gh.workflow_runs(workflow_name, branch):
        if "head_branch" not in run or run["head_branch"] != branch:
            continue
        if "conclusion" not in run or run["conclusion"] != "success":
            continue
        artifacts = gh.list_artifacts(run["id"])
        for artifact in artifacts:
            artifact_name = artifact["name"]
            if not artifact_name.endswith("-installable"):
                continue
            _, artifact_scheme = derive_platform_suffix_and_scheme(artifact_name)
            if artifact_scheme == scheme:
                return run["id"]
    raise Exception(f"Could not find a successful run for {workflow_name} on {branch} branch with scheme {scheme}")


async def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('run_id', type=str)
    parser.add_argument(
        '--override-name', type=str,
        default=os.environ.get("GH_DISTRIBUTE_TOOLCHAIN_OVERRIDE_NAME"))
    parser.add_argument(
        '--only-swift-sdk', action='store_true')
    options = derive_options_from_args(sys.argv[1:], parser)

    secrets = Secrets.derive()
    gh = GitHub(secrets.GITHUB_TOKEN, "swiftwasm/swiftwasm-build")
    swift_gh = GitHub(secrets.GITHUB_TOKEN, "swiftwasm/swift")
    swiftwasm_build_dir = os.path.join(os.path.dirname(__file__), "..")
    os.chdir(swiftwasm_build_dir)
    run_id = options.run_id
    if run_id == "latest":
        run_id = latest_success_run_id(
            gh, workflow_name="build-toolchain.yml", branch="main", scheme=options.scheme)
        run_id = str(run_id)
        print(f"Automatically determined run_id: {run_id}")
    await Distribution(gh, swift_gh, run_id, secrets,
                       options.dry_run, options.verbose).run(options)


if __name__ == '__main__':
    asyncio.run(main())
